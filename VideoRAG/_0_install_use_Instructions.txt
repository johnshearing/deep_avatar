Instructions to install and use these libraries.

############## The commands is this section are used to install the libraries ####################

# I happen to be using Ubuntu on WSL.

# Do these only once to create a virtual environment and install packages.
cd <location where you want to install the VideoRAG library>
git clone https://github.com/HKUDS/VideoRAG.git
cd VideoRAG
conda create --name vrag_env python=3.11

# Now activate the vrag_env virtual environment with the following command.
# any time when you wish to use the VideoRAG library or install the required packages that the library uses, the virtual environment must be activated.
conda activate vrag_env

# To deactivate an active virtual environment, use the following command.
# The vrag_env must be active when installing packages or when using the VideoRAG library
# Deactivate this virtual environment when you are finished using the VideoRAG library if you want.
conda deactivate

# Creates a better looking prompt that takes up less space on the screen.
export PS1='($CONDA_DEFAULT_ENV) \w\$ '

# Before using the VideoRAG library, install these packages while the vrag_env virtual environment is active.
pip install numpy==1.26.4
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2
pip install accelerate==0.30.1
pip install bitsandbytes==0.43.1
pip install moviepy==1.0.3
pip install git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d
pip install timm ftfy regex einops fvcore eva-decord==0.6.1 iopath matplotlib types-regex cartopy
pip install ctranslate2==4.4.0 faster_whisper==1.0.3 neo4j hnswlib xxhash nano-vectordb
pip install transformers==4.37.1
pip install tiktoken openai tenacity

# These packages must also be installed in order to use the custom scripts in the deep-avatar library.
# Before using the deep-avatar library, install these packages while the vrag_env virtual environment is active.
pip install ollama
pip install yt-dlp
pip install openai-whisper
pip install sentence-transformers


# Install ImageBind using the provided code in this repository, where we have removed the requirements.txt to avoid environment conflicts.
cd ImageBind
pip install .


# Then, please download the necessary checkpoints in the repository's root folder for MiniCPM-V, Whisper, and ImageBind as follows:


# Make sure you have git-lfs installed (https://git-lfs.com)
sudo apt update
sudo apt install git-lfs


git lfs install

# minicpm-v
git lfs clone https://huggingface.co/openbmb/MiniCPM-V-2_6-int4

# whisper
git lfs clone https://huggingface.co/Systran/faster-distil-whisper-large-v3

# imagebind
mkdir .checkpoints
cd .checkpoints
wget https://dl.fbaipublicfiles.com/imagebind/imagebind_huge.pth
cd ../


Your final directory structure after downloading all checkpoints should look like this:

VideoRAG
├── .checkpoints
├── faster-distil-whisper-large-v3
├── ImageBind
├── LICENSE
├── longervideos
├── MiniCPM-V-2_6-int4
├── README.md
├── reproduce
├── notesbooks
├── videorag
├── VideoRAG_cover.png
└── VideoRAG.png


To run the script without GPU. CPU only.
CUDA_VISIBLE_DEVICES=-1 python3 _index_videos_02.py

############## End of: The commands is this section are used to install the libraries ####################



############## The commands is this section are used to trouble shoot the GPU ####################
# Check GPU installation in common directories:
ls /usr/local/cuda*
ls /usr/local/cuda/lib64/libcudart*
ls /usr/local/cuda/bin
ls /usr/local/cuda-*/bin
ls /opt/cuda/bin

# Locate the nvcc executable in the system's path.
which nvcc

# This one takes a while to run.
sudo find / -name nvcc 2>/dev/null

# Check for installed CUDA packages:
dpkg -l | grep cuda

# Check if have NVIDIA Cuda Compiler
nvcc --version

# Check GPU info for Windows:
nvidia-smi

# These commands run a test on the GPU.
python3 /home/js/faiss_gpu/_test_gpu_01.py
python3 /home/js/faiss_gpu/_test_gpu_02.py

# Check installed packages with dpkg:
dpkg -l | grep cudnn

# Look for cuDNN files in the CUDA directory:ls -l /usr/local/cuda/include | grep cudnn
ls -l /usr/local/cuda/lib64 | grep cudnn
ls -l /usr/local/cuda/include | grep cudnn

# If you installed via apt, you can check with:
apt list --installed | grep cudnn

# If you installed from the NVIDIA tar file, verify the header files exist:
find /usr -name cudnn.h

# Check cuDNN version programmatically:
cat /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2


# Python commands for REPL. Check PyTorch sees cuDNN
import torch
print(torch.backends.cudnn.version())  # Should print 8900 or similar
print(torch.backends.cudnn.is_available())  # Should be True


############## End of: The commands is this section are used to trouble shoot the GPU ####################




############## The commands is this section are for running the scripts in this repository ####################


# To index videos so that the information is availale for query, use the following commands at the bash terminal.

# Navigate to the VideoRAG directory.
cd VideoRAG

# Activate the vrag_env virtual environment with the following command.
conda activate vrag_env

# The first command below indexes all the videos at a specified YouTube channel.
# The second command below indexes all the videos specifed in a local text file.
# If the text file command is used then enter one URL per line in the file.

# The list of videos has a zero index. 
# This means that the very first video in the list is indicated by the number zero.
# The second video in the list is indicated by the number 1 and so on.

# Default value for --starting-index is 0 if nothing is entered. 
# A value of 0 means > Start at the beginning of list of videos. 

# Default value for --ending-index is None if nothing is entered. 
# A value of None means “process all the way to the end of the list”
# A value of 0 entered means > stop after processing the first video.

# Include --enable-video at the end of the command if you want to process video.
# If --enable-video is not included in the command then only audio will be processed. 

python3 _1_index_videos_04.py \
  --channel-url "https://www.youtube.com/@abrahamhickstips/videos" \
  --audio-dir "_audio_files" \
  --mp4-dir "_mp4_files" \
  --workdir "_audiorag_workdir" \
  --starting-index 0 \
  --ending-index 0 \
  --enable-video

python3 _1_index_videos_04.py \
  --urls-file "_video_list.txt" \
  --audio-dir "_audio_files" \
  --mp4-dir "_mp4_files" \  
  --workdir "_audiorag_workdir" \
  --starting-index 0 \
  --ending-index 0 \
  --enable-video


  # To query the indexes about the videos, open the file "_2_query_indexes_01.py" in a text editor and modify the query.
  # Then run the following command at the bash terminal:
  python3_2_query_indexes_01.py



##############End of: The commands is this section are for running the scripts in this repository ####################




##############The commands is this section are for troubleshooting the python scripts ####################


Finds files in a dir and all subdirs which contain the search phrase "9xf-RcWQLDI"
pcregrep -r -M -l "9xf-RcWQLDI" . 2>/dev/null
  

